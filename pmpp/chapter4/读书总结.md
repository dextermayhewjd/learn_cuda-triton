# Chapter 4 计算架构和调度

## 4.1 现代gpu架构

A100 的 sm数量是 108个SM流处理器， 

- 每个sm单元有 64个核 总共6912个  
- 每个SM单元有 4个 Tesnor core 核心， 完整gpu共432个Tensor 核心

H100 的 sm数量是 114个SM流处理器

- 每个sm单元有 128个核 总共14592个  
- 每个SM单元配备4个第四代Tensor核心，每个完整GPU配备456个Tensor核心 

Blackwell (GB200 NVL72)

- SM: 8640 (120 × 72)
- Tensor Core: 34,560
- HBM: ~13.8 TB
- 单一 NVLink 计算域

## 4.2 块调度

- 一个块中的所有线程都会同时分配给一个sm
- sm数量有限， 同时分配给每个sm的块数量有限
- 排队机制会确保 新的block执行完时分配新的block给SM
- 线程因为在一个sm里 能确保线程能够
  - 1. 访问共享内存  
  - 2. 屏蔽同步  

# 4.3 同步和透明可拓展性

- 一个块中的线程通过 `_ _ syncthreads( )` (两个_ 符号)  
等同一个block 中每个线程都到达了该位置再进入下一个阶段

- Barrier synchronization ----- for coordinating parallel activities
  - eg. four people shopping and wait for all to leave  


- __ syncthreads ( )使用规范
  - it must be executed by all threads in a block 
    - cannot be put in a if-else statement , if only one __ syncthreads ( ) is placed since it violate the rule
    必须被所有一个block的所有线程执行 不能在if 或者else的单个中执行 否则会死锁

- cuda runtime system可以以任何相对顺序执行块
 因为块之间没有同步约束

## 4.4 线程束 warp 和SIMD 硬件

### 4.4.1 warp的基本分配策略

- 一旦一个块被分配给SM，就会被进一步划分为32个线程单元 称之为线程束warp
- 目前线程束都是32个线程

- 如果一个block是被组织成一维的数组，那么warp从 threadidx.x = 0 开始
到31结束
  - 如果是32的倍数，那么被分成个
  - 如果不是 余数会被划分为另一个warp

- 如果是多维数组，会先线性投影到线性布局， x从小到大，然后再是y
![alt text](5277a6b16763aa119a6e5463f2839c6.png)
### 4.4.2 SIMD和 warp

- 在任意时刻，为warp的所有thread给提取并执行一条指令
- a100 的 sm 里64个核心， 被分成了4个processing block,每个处理块 有16个核心
- 同一个warp 的thread被分配到一个processing block.
- 同一个processing block为warp中所有thread 
  获取 并且执行 这些指令instruction
- 由于这些线程对数据的不同部分执行了相同的指令，被称之为SIMD

## 4.5 控制发散

少写if else 
否则要分路径执行
 ![alt text](2920b54278a390f66b930b5f79affff.png)

如果同一个warp内 所有线程必须都完成某个阶段
那么必须要依靠 __ syncwarp() __ 来保证正确性

## 4.6 Warp scheduling and latency tolerance
一个SM 通常被分配非常多线程 
例如一个 warp 有 32 个线程

- 一个 SM 可能只有 64 或 128 个 FP32 cores  
- 但 SM 上常驻的线程可能是 2048 个  

旧架构：

- 一个 SM = 一个 warp 同时执行 → 比如 32 线程 lockstep 执行同一条指令


新架构：

- 一个 SM 可以并行调度多个 warp
- 例如 Ampere 可以 dual-issue，甚至同时来自不同 warp 的指令

原因是warp执行到需要等待启动的长延迟操作， 这种操作称之为latency tolerance
